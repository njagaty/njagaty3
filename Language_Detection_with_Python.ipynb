{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVIr+IB4JGRmM1SzwAiE6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njagaty/njagaty3/blob/main/Language_Detection_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB8TFe24s3ku",
        "outputId": "4d2a4dfa-6a80-4ec4-b16e-909d96bb6376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bhagwan Sri Satya Sai Baba Ji ki jay\n"
          ]
        }
      ],
      "source": [
        "print(\"Bhagwan Sri Satya Sai Baba Ji ki jay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task of language detection comes into use when you are working on a very large dataset that contains data in different languages. Suppose you want to create an even driven program where the final output depends on the language which the user provides as an input. So it is important to first detect the language of the text provided by the user before taking any action. So, in this article, I will take you through the task of language detection with Python."
      ],
      "metadata": {
        "id": "VDyuooI8tRGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eyA5bAktUUk",
        "outputId": "a17ee2e9-6bf1-4930-9df0-bc0b4dada930"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=3b9b123f0f6685ca7acc2fc33d184167f6b335e1719c35226e6e498a2f3b9abf\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect\n",
        "text = input(\"Enter any text in any language: \")\n",
        "print(detect(text))"
      ],
      "metadata": {
        "id": "qO_muJhGtnt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}